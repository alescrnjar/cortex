{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import sys \n",
    "sys.path.append('../../LM_Tests/My_LM_Library/')\n",
    "import myRAGtools\n",
    "import myRAGtools_utils\n",
    "key_file='../../LM_Tests/openai_api_key.txt'\n",
    "with open(key_file, 'r') as file:\n",
    "    openai_api_key=file.read()\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.uname()[1]=='auros': pydirec='/home/alessandro/Documents/LocalColabFold_Files/localcolabfold/colabfold-conda/lib/python3.10/site-packages/cortex/'\n",
    "py_scripts=[\n",
    "pydirec+'model/block/__init__.py',\n",
    "pydirec+'model/block/_conv1d_resid_block.py',\n",
    "pydirec+'model/root/_conv1d_root.py',\n",
    "pydirec+'model/root/_abstract_root.py',\n",
    "pydirec+'model/root/__init__.py',\n",
    "pydirec+'model/leaf/_seq_regressor_leaf.py',\n",
    "pydirec+'model/leaf/_denoising_lm_leaf.py',\n",
    "pydirec+'model/leaf/_abstract_leaf.py',\n",
    "pydirec+'model/leaf/_classifier_leaf.py',\n",
    "pydirec+'model/leaf/__init__.py',\n",
    "pydirec+'model/leaf/_regressor_leaf.py',\n",
    "pydirec+'model/tree/_seq_model_tree.py',\n",
    "pydirec+'model/tree/_abstract_tree.py',\n",
    "pydirec+'model/tree/__init__.py',\n",
    "pydirec+'model/trunk/_abstract_trunk.py',\n",
    "pydirec+'model/trunk/_sum_trunk.py',\n",
    "pydirec+'model/trunk/__init__.py',\n",
    "pydirec+'model/_infer_with_model.py',\n",
    "pydirec+'model/_weight_averaging.py',\n",
    "pydirec+'model/branch/__init__.py',\n",
    "pydirec+'model/branch/_abstract_branch.py',\n",
    "pydirec+'model/branch/_conv1d_branch.py',\n",
    "pydirec+'model/__init__.py',\n",
    "pydirec+'model/elemental/_sine_pos_encoder.py',\n",
    "pydirec+'model/elemental/_mean_pooling.py',\n",
    "pydirec+'model/elemental/_functional.py',\n",
    "pydirec+'model/elemental/_expression.py',\n",
    "pydirec+'model/elemental/_layernorm.py',\n",
    "pydirec+'model/elemental/__init__.py',\n",
    "pydirec+'model/elemental/_ddp_standardize.py',\n",
    "pydirec+'model/elemental/_apply.py',\n",
    "pydirec+'config/hydra/__init__.py',\n",
    "pydirec+'config/__init__.py',\n",
    "pydirec+'exceptions.py',\n",
    "pydirec+'metrics/_spearman_rho.py',\n",
    "pydirec+'metrics/_edit_dist.py',\n",
    "pydirec+'metrics/__init__.py',\n",
    "pydirec+'cmdline/optimize_sequences.py',\n",
    "pydirec+'cmdline/__init__.py',\n",
    "pydirec+'cmdline/train_cortex_model.py',\n",
    "pydirec+'constants/_protein_constants.py',\n",
    "pydirec+'constants/__init__.py',\n",
    "pydirec+'client.py',\n",
    "pydirec+'logging/_wandb_setup.py',\n",
    "pydirec+'logging/__init__.py',\n",
    "pydirec+'optim/generative/__init__.py',\n",
    "pydirec+'optim/generative/_lambo.py',\n",
    "pydirec+'optim/_initialization.py',\n",
    "pydirec+'optim/__init__.py',\n",
    "pydirec+'io/_load_model_checkpoint.py',\n",
    "pydirec+'io/_verify_checksum.py',\n",
    "pydirec+'io/_parse_s3_path.py',\n",
    "pydirec+'io/_md5.py',\n",
    "pydirec+'io/_verify_integrity.py',\n",
    "pydirec+'io/_load_hydra_config.py',\n",
    "pydirec+'io/_download.py',\n",
    "pydirec+'io/__init__.py',\n",
    "pydirec+'assets/protein_seq_tokenizer_32/__init__.py',\n",
    "pydirec+'assets/__init__.py',\n",
    "pydirec+'consts.py',\n",
    "pydirec+'attribution/_occlusion.py',\n",
    "pydirec+'attribution/__init__.py',\n",
    "pydirec+'tokenization/_protein_seq_tokenizer.py',\n",
    "pydirec+'tokenization/_cached_bert_tokenizer.py',\n",
    "pydirec+'tokenization/__init__.py',\n",
    "pydirec+'data/samplers/functional/_round_robin_longest.py',\n",
    "pydirec+'data/samplers/functional/__init__.py',\n",
    "pydirec+'data/samplers/_randomized_minority_sampler.py',\n",
    "pydirec+'data/samplers/_minority_upsampler.py',\n",
    "pydirec+'data/samplers/__init__.py',\n",
    "pydirec+'data/data_module/_task_data_module.py',\n",
    "pydirec+'data/data_module/__init__.py',\n",
    "pydirec+'data/__init__.py',\n",
    "pydirec+'data/dataset/_data_frame_dataset.py',\n",
    "pydirec+'data/dataset/_transformed_dataset.py',\n",
    "pydirec+'data/dataset/_tape_stability.py',\n",
    "pydirec+'data/dataset/_tape_fluorescence.py',\n",
    "pydirec+'data/dataset/__init__.py',\n",
    "pydirec+'data/dataset/_rfp_dataset.py',\n",
    "pydirec+'acquisition/__init__.py',\n",
    "pydirec+'acquisition/_graph_nei.py',\n",
    "pydirec+'task/_denoising_lm_task.py',\n",
    "pydirec+'task/_regression.py',\n",
    "pydirec+'task/_sequence_regression.py',\n",
    "pydirec+'task/__init__.py',\n",
    "pydirec+'task/_classification.py',\n",
    "pydirec+'task/_abstract_task.py',\n",
    "pydirec+'telemetry.py',\n",
    "pydirec+'corruption/_gaussian_corruption.py',\n",
    "pydirec+'corruption/_mask_corruption.py',\n",
    "pydirec+'corruption/_diffusion_noise_schedule.py',\n",
    "pydirec+'corruption/__init__.py',\n",
    "pydirec+'corruption/_abstract_corruption.py',\n",
    "pydirec+'transforms/_tokenize_igg_ag_df.py',\n",
    "pydirec+'transforms/functional/_tokenize_igg_ag_df.py',\n",
    "pydirec+'transforms/functional/__init__.py',\n",
    "pydirec+'transforms/_transform.py',\n",
    "pydirec+'transforms/_hf_tokenizer_transform.py',\n",
    "pydirec+'transforms/__init__.py',\n",
    "pydirec+'binary/__init__.py',\n",
    "pydirec+'__init__.py',\n",
    "pydirec+'util.py',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(text_splits)=1\n",
      "len(text_splits)=4\n",
      "len(text_splits)=20\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=3\n",
      "len(text_splits)=7\n",
      "len(text_splits)=1\n",
      "len(text_splits)=7\n",
      "len(text_splits)=2\n",
      "len(text_splits)=12\n",
      "len(text_splits)=33\n",
      "len(text_splits)=8\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=3\n",
      "len(text_splits)=1\n",
      "len(text_splits)=4\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=4\n",
      "len(text_splits)=1\n",
      "len(text_splits)=2\n",
      "len(text_splits)=2\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=9\n",
      "len(text_splits)=1\n",
      "len(text_splits)=0\n",
      "len(text_splits)=0\n",
      "len(text_splits)=2\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=9\n",
      "len(text_splits)=0\n",
      "len(text_splits)=3\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=9\n",
      "len(text_splits)=2\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=25\n",
      "len(text_splits)=2\n",
      "len(text_splits)=1\n",
      "len(text_splits)=3\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=16\n",
      "len(text_splits)=1\n",
      "len(text_splits)=0\n",
      "len(text_splits)=0\n",
      "len(text_splits)=1\n",
      "len(text_splits)=5\n",
      "len(text_splits)=1\n",
      "len(text_splits)=6\n",
      "len(text_splits)=5\n",
      "len(text_splits)=1\n",
      "len(text_splits)=2\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=10\n",
      "len(text_splits)=1\n",
      "len(text_splits)=0\n",
      "len(text_splits)=5\n",
      "len(text_splits)=3\n",
      "len(text_splits)=2\n",
      "len(text_splits)=2\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=1\n",
      "len(text_splits)=12\n",
      "len(text_splits)=3\n",
      "len(text_splits)=7\n",
      "len(text_splits)=5\n",
      "len(text_splits)=1\n",
      "len(text_splits)=7\n",
      "len(text_splits)=3\n",
      "len(text_splits)=5\n",
      "len(text_splits)=1\n",
      "len(text_splits)=2\n",
      "len(text_splits)=6\n",
      "len(text_splits)=1\n",
      "len(text_splits)=4\n",
      "len(text_splits)=2\n",
      "len(text_splits)=2\n",
      "len(text_splits)=1\n",
      "len(text_splits)=3\n",
      "len(text_splits)=2\n",
      "len(text_splits)=1\n",
      "len(text_splits)=5\n",
      "len(text_splits)=1\n",
      "len(text_splits)=2\n",
      "348\n"
     ]
    }
   ],
   "source": [
    "py_splits=myRAGtools.get_splits(py_scripts, chunk_size=1000, chunk_overlap=0, correct_spelling=False, doctype='python')\n",
    "print(len(py_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_retriever=myRAGtools.get_retriever_for_text_splits(py_splits, k_to_retrieve=4, vectorstore='FAISS', distance_strategy='COSINE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To build a custom dataset for Cortex, you can create a class that inherits from the DataFrameDataset \n",
      "class and define the necessary attributes and methods. This custom dataset class should include the \n",
      "necessary data processing and tokenization functions, as well as the initialization method to handle \n",
      "dataset downloading and other configurations. Additionally, you may need to import relevant libraries \n",
      "such as pandas and define the download URL for the dataset.\n"
     ]
    }
   ],
   "source": [
    "question='How do I build a custom dataset for Cortex?'\n",
    "answer=myRAGtools.rag_chain(question,py_retriever,\n",
    "                            #premise='Report one or multiple sentences from the original text, that are the most relevant to answer the following question. '\n",
    "                            )\n",
    "myRAGtools_utils.print_force_new_line(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The protein aminoacid alphabet can be changed into a different alphabet by modifying the CANON_AMINO_ACIDS \n",
      "variable in the _protein_constants.py file.\n"
     ]
    }
   ],
   "source": [
    "question='How do I change the protein aminoacid alphabet into a different alphabet?'\n",
    "answer=myRAGtools.rag_chain(question,py_retriever,\n",
    "                            #premise='Report one or multiple sentences from the original text, that are the most relevant to answer the following question. '\n",
    "                            )\n",
    "myRAGtools_utils.print_force_new_line(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
